{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8d7f67-117f-421c-8486-92a45dd17236",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'> Orthogonality</h1>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Esse capítulo é dedicado ao estudo da ortogonalidade entre espaços. \n",
    "        </li>\n",
    "        <li>\n",
    "            Entendemos dois espaços $V$ e $W$ como ortogonais, caso o dot-product entre cada um de seus vetores se resultar em 0 (seguindo a Lei do Cosseno).\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e21b2c-2e33-481f-8801-0b5119a936f8",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $v^{T}\\cdot{w}=0, \\forall{v\\in{V}}, \\forall{w\\in{W}}\\iff{V\\perp{W}}$\n",
    "            <figcaption style='font-size:15px'> Definição formal da ortogonalidade entre espaços</figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ef06f-1fc3-47c1-9177-0262a199021c",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> 4.1 Orthogonality of the Four Subspaces</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>  \n",
    "            Nessa seção, aplicamos o conceito da ortogonalidade no estudo dos 4 sub-espaços fundamentais da Álgebra Linear. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dabc44b-ec71-4162-8c7e-85af7bcaea49",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Nullspace and Row Space</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Todo o Nullspace e Row Space de uma matriz $A$ serão ortogonais, em consonância com suas próprias definições.\n",
    "        </li>\n",
    "        <li>\n",
    "            Como todo produto linear entre cada vetor-linha de $A$ e vetor-coluna $x\\in{N(A)}$ resultará em 0, podemos dizer que:\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425ffea-20bc-4b87-815d-cc08f3792403",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $N(A)\\perp{C(A^{T})}$\n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc4009-3610-4ea7-82c5-a32ce2b1ec44",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Left Nullspace and Column Space</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Usando a mesma lógica, podemos comprovar também que o Left Nullspace e Column Space de $A$ também são ortogonais. \n",
    "        </li>\n",
    "        <li>\n",
    "            Considerando que os vetores-linhas de $A^{T}$ são as colunas de $A$, e que o produto escalar entre eles e os membros do basis de $N(A^{T})$ sempre será 0, podemos concluir que Left Nullspace e Column Space serão sempre ortogonais. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2fd742-18dd-4a96-a310-a3b412030091",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $N(A^{T})\\perp{C(A)}$\n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282c0ed-8c3f-47d7-8526-9cb9c5bed66d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Orthogonal Complements</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'>\n",
    "        <li>\n",
    "            Quando um sub-espaço $V$ contém todos os vetores que são ortogonais a outro sub-espaço $W$, dizemos que aquele é o complemento ortogonal deste.\n",
    "        </li>\n",
    "        <li>\n",
    "            No caso, tanto o Nullspace e Row Space, quanto o Left Nullspace e Column Space de $A$ são complementos ortogonais de um do outro. \n",
    "        </li>\n",
    "     </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97c2f0-af41-4e61-8074-61d5ae5e8229",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $V^{\\perp}=W\\iff{W^{\\perp}}=V$\n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f602d6-eb03-4f59-a6ab-307c85e23086",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Fundamental Theorem of Linear Algebra (Part 2)</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'>\n",
    "        <li>\n",
    "            As descobertas que fizemos constituem a Segunda Parte do Teorema Fundamental da Álgebra Linear.\n",
    "        </li>\n",
    "        <li>\n",
    "            Enquanto a primeira se voltava à dimensionalidade de cada sub-espaço fundamental, essa destaca a ortogonalidade entre eles:\n",
    "            <ol> \n",
    "                <li>\n",
    "                    $N(A)\\perp{C(A^{T})}$\n",
    "                </li>\n",
    "                <li>\n",
    "                    $N(A^{T})\\perp{C(A)}$\n",
    "                </li>\n",
    "            </ol>\n",
    "        </li>\n",
    "     </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8804b8-a6a8-452c-8b5c-57528642004a",
   "metadata": {},
   "source": [
    "<h2 style='font-size:30px'> 4.2 Projections</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>  \n",
    "            Essa seção é voltada ao estudo de projeções de vetores.\n",
    "        </li>\n",
    "        <li>\n",
    "            Entendemos como \"projeção\" a parte de um vetor contida no(s) eixo(s) especificado(s). A linha que o liga com sua projeção deverá ser perpendicular ao eixo sob análise. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b7284-0a54-46dd-8142-73cb4fb77cd6",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Exemplo</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Analisando o vetor $b=\\begin{bmatrix}2\\\\3\\\\7\\end{bmatrix}$, entendemos a sua projeção no eixo $z$ como $\\begin{bmatrix}0\\\\0\\\\7\\end{bmatrix}$ e no plano $xy$ $\\begin{bmatrix}2\\\\3\\\\0\\end{bmatrix}$.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4b5fc-8c19-43bb-8e8f-e251299038c6",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Projection Matrices</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'>\n",
    "        <li>\n",
    "            As matrizes de projeção são usadas para extrair as projeções de um vetor nos eixos desejados.\n",
    "        </li>\n",
    "     </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a607c7-0a66-461a-8c2c-8244580563d2",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $P_{1}b=\\begin{bmatrix}0&0&0\\\\0&0&0\\\\0&0&1\\\\\\end{bmatrix}\\begin{bmatrix}2\\\\3\\\\7\\end{bmatrix}=\\begin{bmatrix}0\\\\0\\\\7\\end{bmatrix}$\n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3be0b3-34c2-45ff-be6e-b3bf956dca6e",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $P_{2}b=\\begin{bmatrix}1&0&0\\\\0&1&0\\\\0&0&0\\\\\\end{bmatrix}\\begin{bmatrix}2\\\\3\\\\7\\end{bmatrix}=\\begin{bmatrix}2\\\\3\\\\0\\end{bmatrix}$\n",
    "            <figcaption style='font-size:15px'> \n",
    "                Podemos obter as projeções de $b$ mencionadas usando as matrizes $P_{1}$ e $P_{2}$.\n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a687314-1467-4694-bfec-0c917028608b",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Projection Onto a Line</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'>\n",
    "        <li>\n",
    "            Da mesma forma que fizemos com eixos, podemos criar projeções $p$ de vetores baseadas em linhas $a=(a_{1},a_{2},\\ldots,a_{m})$. Vale notar que estas devem passar pela origem do plano.\n",
    "        </li>\n",
    "        <li>\n",
    "            Essa projeção será dada como $p=\\hat{x}a,\\hat{x}\\in\\mathbb{R}$. Consideramos como \"erro\" o vetor gerado pela diferença entre o original $b$ e sua projeção $e=b-\\hat{x}a$.\n",
    "        </li>\n",
    "        <li>\n",
    "            $e$ no caso será a linha ortogonal a $a$ que a conectará com $p$.\n",
    "        </li>\n",
    "     </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a5bd3c-4531-4c7f-92b8-ae3cb4812433",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Matriz de Projeção</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Sabendo que $e$ será ortgonal a $a$, podemos extrair a seguinte relação: \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d8492-b98e-4c77-921f-bfcf57cbf075",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $$\\begin{align*}a\\cdot{e}&=0\\\\ \n",
    "            \\iff a\\cdot{(b-\\hat{x}a)}&=0 \\\\\n",
    "            \\iff a\\cdot{b}-\\hat{x}a\\cdot{a}&=0\\\\\n",
    "            \\iff\\hat{x}=\\frac{a\\cdot{b}}{a\\cdot{a}}&=\\frac{a^{T}b}{a^{T}a}\n",
    "            \\end{align*}\n",
    "            $$\n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c4b0e-86dc-465b-a33f-59772c5ab614",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Com isso, podemos concluir que a matriz de projeção de $a$ será $P=\\frac{aa^{T}}{a^{T}a}$. \n",
    "        </li>\n",
    "        <li>\n",
    "            Seu rank será 1, uma vez que o sub-espaço onde estamos fazendo a projeção é unidimensional.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db5e4af-0167-49c1-8948-21fb76215f1f",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $p=a\\hat{x}=a\\frac{a^{T}b}{a^{T}a}=Pb\\text{, }P=\\frac{aa^{T}}{a^{T}a}$\n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d8587-79de-4488-a39f-6fc2c5a038c9",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Repare que conseguimos decompor $b$ em $p$, sua parte em $a$ e $e$, sua parte perpendicular à linha, como demonstra a figura.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8adbe-5de4-4a4d-85d4-eee4aad2b2c8",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            <img src='img/04-b-decomposition.png'>        \n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527cf3ad-e2d7-4d67-a4a6-e1dce584c80e",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Projeções Perpendiculares</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Podemos reparar que a matriz $I-P$ sempre gerará o vetor $e$. Isso porque $(I-P)b=b-p=e$.\n",
    "        </li>\n",
    "        <li>\n",
    "            Portanto, podemos afirmar que ela sempre projetará $b$ ao sub-espaço perpendicular ao definido por $a$.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7fdf7-e8de-4e6b-9746-37d52c7ee94d",
   "metadata": {},
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Projection Onto a Subspace</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'>\n",
    "        <li>\n",
    "            Seja $\\mathbb{R}^{m}$ um sub-espaço definido pelos vetores $a_{1},\\ldots,a_{n}$ linearmente independentes, a projeção do vetor $b$ poderá ser definida como a combinação $p=\\hat{x}_{1}a_{1}+\\ldots+\\hat{x}_{n}a_{n}=A\\hat{x}$ que mais se aproxima dele.\n",
    "        </li>\n",
    "        <li>\n",
    "            No caso, $A$ será a matriz com todos os vetores-base do sub-espaço.\n",
    "        </li>\n",
    "        <li>\n",
    "            Assim como em casos uni-dimensionais, o vetor de erro $b-A\\hat{x}$ deverá ser ortogonal ao sub-espaço, ou seja, a cada um de seus vetores-bases.\n",
    "        </li>\n",
    "     </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed374c-a297-4ac9-9d7c-94cae539cd28",
   "metadata": {},
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Projection Matrix</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A partir dessa relação de ortogonalidade, conseguimos estimar a matriz $P$ de projeção desse sub-espaço.\n",
    "        </li>\n",
    "        <li>\n",
    "            Começamos por identificar o vetor $\\hat{x}$ ótimo que cria a projeção de $b$ em $A$.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87c0fc7-7ca5-4035-892b-76fc335aaa44",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $$\\begin{align*}\n",
    "            A^{T}(b-A\\hat{x})&=0\\iff\\\\\n",
    "            A^{T}A\\hat{x}&=A^{T}b\\iff\\\\\n",
    "            \\hat{x}&=(A^{T}A)^{-1}A^{T}b\n",
    "            \\end{align*}\n",
    "            $$\n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c65f5-863c-4cba-860f-b59ec169662b",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            A partir daí, podemos deduzir o vetor $p$.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725247fd-fdb0-4366-bd6b-182edc809550",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $$\\begin{align*}\n",
    "            p=A\\hat{x}=A(A^{T}A)^{-1}A^{T}b\n",
    "            \\end{align*}\n",
    "            $$\n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7910ec-e18c-4eec-b777-a40c35426c31",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            Seja $P$ a matriz responsável por projetar $b$ no sub-espaço, podemos então defini-la como:\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08a928-7ad1-467e-85d4-da026df45a13",
   "metadata": {},
   "source": [
    " <center style='margin-top:20px;font-size:20px'> \n",
    "        <figure>\n",
    "            $$\\begin{align*}\n",
    "            P=A(A^{T}A)^{-1}A^{T}\n",
    "            \\end{align*}\n",
    "            $$\n",
    "            <figcaption style='font-size:15px'> \n",
    "            </figcaption>\n",
    "        </figure>\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4820d0-e684-4a4c-a4a6-95525625c1e0",
   "metadata": {},
   "source": [
    "<h5 style='font-size:25px;font-style:italic;text-decoration:underline'> Uso de $A^{T}$</h5>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li>\n",
    "            O uso de $A^{T}$ na demonstração acima foi possível devido às propriedades de ortogonalidade de sub-espaços estudadas no início do capítulo.\n",
    "        </li>\n",
    "        <li>\n",
    "            Como sabemos que todo vetor $e$ é ortogonal a $A$, podemos afirmar que esse pertence a $N(A^{T})$ [$C(A)\\perp{N(A^{T})}$].\n",
    "        </li>\n",
    "        <li>\n",
    "            Com isso, a relação $A^{T}(b-Ax)=0$ se torna válida!\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8050c98a-29ac-4c65-8f7e-0bf1cb4a4675",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 38191b5] Continuar de \"The key step was\" p.222\n",
      " 1 file changed, 91 insertions(+), 7 deletions(-)\n",
      "Enumerating objects: 5, done.\n",
      "Counting objects: 100% (5/5), done.\n",
      "Delta compression using up to 24 threads\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 907 bytes | 907.00 KiB/s, done.\n",
      "Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To https://github.com/felipesveiga/linear-algebra.git\n",
      "   53e2db4..38191b5  master -> master\n"
     ]
    }
   ],
   "source": [
    "! git add .\n",
    "! git commit -am 'Continuar de \"In our experience, a problem that involves\" (p.223)' \n",
    "! git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f77e099-f352-460f-82fb-fcb2adebd6c0",
   "metadata": {},
   "source": [
    "<p style='color:red'> Fiz Example III; Continuar de \"In our experience, a problem that involves\" (p.223); \"Acho que apenas vou entender o porquê de $x_{r}$ ser um componente de $C(A^{T})$ lendo a seção 4.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
